{
  "name": "service-runner",
  "version": "1.3.1",
  "description": "Generic nodejs service supervisor / cluster runner",
  "main": "service-runner.js",
  "bin": {
    "service-runner": "./service-runner.js"
  },
  "scripts": {
    "start": "./service-runner.js",
    "test": "mocha"
  },
  "repository": {
    "type": "git",
    "url": "git://github.com/wikimedia/service-runner.git"
  },
  "keywords": [
    "supervisor",
    "cluster",
    "logging",
    "statsd"
  ],
  "author": {
    "name": "Wikimedia service team",
    "email": "services@wikimedia.org"
  },
  "license": "Apache-2.0",
  "bugs": {
    "url": "https://github.com/wikimedia/service-runner/issues"
  },
  "homepage": "https://github.com/wikimedia/service-runner",
  "dependencies": {
    "bluebird": "^3.4.0",
    "bunyan": "^1.8.1",
    "bunyan-syslog-udp": "^0.1.0",
    "core-js": "^2.4.0",
    "extend": "^3.0.0",
    "gelf-stream": "^1.1.0",
    "hot-shots": "^2.3.1",
    "js-yaml": "^3.6.1",
    "limitation": "^0.1.8",
    "semver": "^5.1.0",
    "yargs": "^4.7.0"
  },
  "devDependencies": {
    "mocha": "^2.4.5",
    "mocha-jshint": "^2.3.1",
    "mocha-jscs": "^5.0.0",
    "bunyan-prettystream": "git+https://github.com/hadfieldn/node-bunyan-prettystream.git#master"
  },
  "readme": "# service-runner\nGeneric nodejs service runner & supervisor\n\n## Features\n- Supervise and [cluster](http://nodejs.org/api/cluster.html) node services in a generic manner with a minimal interface:\n\n```javascript\nmodule.exports = function (options) {\n    var config = options.config;\n    // Logger instance\n    var logger = options.logger;\n    // Metrics reporter (statsd,log)\n    var metrics = options.metrics;\n\n    // Start the app, returning a promise\n    return startApp(config, logger, metrics);\n}\n```\n\n- standard command line parameters:\n```bash\nUsage: service-runner.js [command] [options]\n\nCommands:\n  docker-start  starts the service in a Docker container\n  docker-test   starts the test process in a Docker container\n  build         builds the service's package and deploy repo\n\nOptions:\n  -n, --num-workers  number of workers to start                    [default: -1]\n  -c, --config       YAML-formatted configuration file\n                                             [string] [default: \"./config.yaml\"]\n  -f, --force        force the operation to execute   [boolean] [default: false]\n  -d, --deploy-repo  build only the deploy repo       [boolean] [default: false]\n  -r, --review       send the patch to Gerrit after building the repo\n                                                      [boolean] [default: false]\n  --verbose          be verbose                       [boolean] [default: false]\n  -v, --version      print the service's version and exit\n                                                      [boolean] [default: false]\n  -h, --help         Show help                                         [boolean]\n```\n- [config loading](#config-loading)\n- flexible logging using bunyan, including logstash support via gelf: `logger.log('info/request', { message: 'foo', uri: req.uri })`\n- [metric reporting](#metric-reporting) using statsd or logging: `statsd.timing('foo.GET.2xx', Date.now() - startTime)`\n- heap dumps\n\n## Usage\n```bash\nnpm install --save service-runner\n```\n\nIn package.json, configure `npm start` to call service-runner:\n```javascript\n  \"scripts\": {\n    \"start\": \"service-runner\"\n  }\n```\nCreate a `config.yaml` file following the spec below. Make sure to point the\nmodule parameter to your service's entry point.\n\nFinally, **start your service with `npm start`**. In npm >= 2.0 (node 0.12 or iojs), you can also pass parameters to `service-runner` like this: `npm start -- -c /etc/yourservice/config.yaml`.\n\nFor node 0.10 support, you can create a small wrapper script like this:\n```javascript\nvar ServiceRunner = require('service-runner');\nnew ServiceRunner().run();\n```\n\nAll file paths in the config are relative to the application base path. \nThe base path is an absolute path to the folder where your application \nis located (where `package.json` file is located).\n\nBy default, we assume that your project depends on `service-runner` and \nyou follow standard node project layout. However, if a custom layout is \nused, you must override the app base path with either:\n- `APP_BASE_PATH` environment variable\n- `app_base_path` config stanza.\n\nWe are also working on a [standard\ntemplate](https://github.com/wikimedia/service-template-node) for node\nservices, which will set up this & other things for you.\n\n### Config loading\n- Default config locations in a project: `config.yaml` for a customized config,\n    and `config.example.yaml` for the defaults.\n- Default top-level config format (**draft**):\n\n```yaml\n# Number of worker processes to spawn.\n# Set to 0 to run everything in a single process without clustering.\nnum_workers: 1\n\n# Number of milliseconds to wait for a heartbeat from worker before killing\n# and restarting it\nworker_heartbeat_timeout: 7500\n\n# Logger info\nlogging:\n  level: info\n  # Sets up sample logging for some 'interesting' events.\n  # Map keys correspond to the full log level names. \n  # Map values specify the probability for such events to be logged\n  # regardless of the configured logging level.\n  sampled_levels:\n    'trace/webrequest': 0.2\n  streams:\n  # Use gelf-stream -> logstash\n  - type: gelf\n    host: logstash1003.eqiad.wmnet\n    port: 12201\n\n# Statsd metrics reporter\nmetrics:\n  type: statsd\n  host: localhost\n  port: 8125\n  batch: # Metrics batching options. Supported only for `statsd` reporter type\n    max_size: 1500 # Max size of the batch buffer (default: 1500)\n    max_delay: 1000  # Max delay for an individual metric in milliseconds (default: 1000)\n\n# Rate limiter (enabled by default)\nratelimit:\n  type: memory\n  # optional: Kademlia backend\n  # type: kad\n  # seeds:\n  #  - 123.456.789.233\n  #  - 456.789.90.2\n\nservices:\n  - name: parsoid\n    # a relative path or the name of an npm package, if different from name\n    # module: ./lib/server.js\n\n    # optionally, a version constraint of the npm package\n    # version: ^0.4.0\n\n    # per-service config\n    conf:\n        port: 12345\n        interface: localhost\n        # more per-service config settings\n```\n\n### Metric reporting\n\nWe basically expose the [node-statsd\ninterface](https://github.com/sivy/node-statsd):\n\n```javascript\n// Timing: sends a timing command with the specified milliseconds\noptions.metrics.timing('response_time', 42);\n\n// Increment: Increments a stat by a value (default is 1)\noptions.metrics.increment('my_counter');\n\n// Decrement: Decrements a stat by a value (default is -1)\noptions.metrics.decrement('my_counter');\n\n// Histogram: send data for histogram stat\noptions.metrics.histogram('my_histogram', 42);\n\n// Gauge: Gauge a stat by a specified amount\noptions.metrics.gauge('my_gauge', 123.45);\n\n// Set: Counts unique occurrences of a stat (alias of unique)\noptions.metrics.set('my_unique', 'foobar');\noptions.metrics.unique('my_unique', 'foobarbaz');\n\n// Incrementing multiple items\noptions.metrics.increment(['these', 'are', 'different', 'stats']);\n\n// Sampling, this will sample 25% of the time\n// the StatsD Daemon will compensate for sampling\noptions.metrics.increment('my_counter', 1, 0.25);\n\n// Tags, this will add user-defined tags to the data\noptions.metrics.histogram('my_histogram', 42, ['foo', 'bar']);\n```\n\nAll metrics are automatically prefixed by the config-provided service name /\ngraphite hierachy prefix to ensure a consistent graphite metric hierarchy.\n\n# Rate limiting\n\nService-runner provides an efficient ratelimiter instance backed by\n[limitation](https://github.com/gwicke/limitation). All per-request checks are\ndone in-memory for low latency and minimal overhead.\n\nTo enforce a limit:\n```javascript\n// Sets limit to 10 req/s, returns true if above limit. \nvar isAboveLimit = options.ratelimiter.isAboveLimit('some_limit_key', 10);\n```\n\nSeveral backends are supported. By default, a simple in-memory backend is\nused. For clusters, a [Kademlia DHT](https://en.wikipedia.org/wiki/Kademlia)\nbased backend is available. Basic Kademlia configuration:\n\n```yaml\nratelimiter:\n  type: kademlia\n  # Cluster nodes\n  seeds:\n    # Port 3050 used by default\n    - 192.168.88.99\n```\n\nAdvanced Kademlia options:\n```yaml\nratelimiter:\n  type: kademlia\n  # Cluster nodes\n  seeds:\n    # Port 3050 used by default\n    - 192.168.88.99\n    - address: some.host.com\n      port: 6030\n\n  # Optional\n  # Address / port to listen on\n  # Default: localhost:3050, random port fall-back if port used\n  listen:\n    address: localhost\n    port: 3050\n  # Counter update / block interval; Default: 10000ms\n  interval: 10000\n```\n\n# Worker status tracking\nAt any point of the execution the service can emit a `service_status` message\nto update the worker status. Statuses are tracked and reported when the worker\ndies or is killed on a timeout, which is useful for debugging failure reasons.\n\nTo emit a status update use the following code:\n```javascript\nprocess.emit('service_status', {\n   type: 'request_processing_begin',\n   uri: req.uri.toString(),\n   some_other_property: 'some_value'\n})\n```\n\nNote: The status message could be an arbitrary object, however it must not contain\ncyclic references.\n\n## Issue tracking\nPlease report issues in [the service-runner phabricator\nproject](https://phabricator.wikimedia.org/tag/service-runner/).\n\n## See also\n- https://github.com/Unitech/PM2 - A lot of features. Focus on interactive\n    use with commandline tools. Weak on logging (only local log files). Does\n    not support node 0.10's cluster module.\n- https://github.com/strongloop/strong-agent - commercial license. Focus on\n    profiling and monitoring, although a lot of the functionality is now\n    available in other libraries.\n- http://krakenjs.com/ - Focused more on MVC & templating rather than\n    supervision & modules\n- https://www.npmjs.com/package/forever-service - Hooks up [forever](https://github.com/foreverjs/forever) with various init systems; could be useful especially on less common platforms that don't have good init systems.\n",
  "readmeFilename": "README.md",
  "_id": "service-runner@1.3.1",
  "_shasum": "715aaad93cb2b24f14c7d142ac5af0f55f454a91",
  "_resolved": "https://registry.npmjs.org/service-runner/-/service-runner-1.3.1.tgz",
  "_from": "https://registry.npmjs.org/service-runner/-/service-runner-1.3.1.tgz"
}
